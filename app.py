import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

# Fonction pour charger le fichier
def load_data(file):
    if file is not None:
        try:
            if file.name.endswith('.csv'):
                df = pd.read_csv(file)
            elif file.name.endswith('.xlsx'):
                df = pd.read_excel(file)
            else:
                st.error("Veuillez t√©l√©charger un fichier CSV ou Excel valide.")
                return None
        except Exception as e:
            st.error(f"Erreur lors du chargement du fichier : {e}")
            return None
        return df
    else:
        st.error("Aucun fichier n'a √©t√© t√©l√©charg√©.")
        return None

# Fonction pour convertir les colonnes datetime en valeurs utilisables
def convert_datetime_columns(df):
    datetime_cols = df.select_dtypes(include=['datetime64']).columns
    for col in datetime_cols:
        df[col+'_year'] = df[col].dt.year
        df[col+'_month'] = df[col].dt.month
        df[col+'_day'] = df[col].dt.day
    df = df.drop(columns=datetime_cols)  # Supprimer les colonnes datetime originales
    return df

# Fonction pour afficher la heatmap de corr√©lation
def show_heatmap(df):
    st.subheader("Matrice de corr√©lation (Heatmap)")

    # Encoder les colonnes cat√©gorielles avec One-Hot Encoding
    df_encoded = pd.get_dummies(df, drop_first=True)  # Convertit les colonnes cat√©gorielles en colonnes num√©riques

    # Calculer la matrice de corr√©lation
    corr = df_encoded.corr()

    # Afficher la heatmap
    plt.figure(figsize=(10, 6))
    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
    st.pyplot(plt)

# Mod√®le de Random Forest pour la pr√©diction
def train_random_forest(df, target_column):
    # Conversion des colonnes datetime
    df = convert_datetime_columns(df)

    # S√©paration des features (X) et de la cible (y)
    X = df.drop(columns=[target_column])
    y = df[target_column]

    # Encoder les colonnes cat√©gorielles avec One-Hot Encoding
    X = pd.get_dummies(X, drop_first=True)

    # Remplir les valeurs manquantes pour les colonnes num√©riques uniquement
    numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns
    X[numeric_columns] = X[numeric_columns].fillna(X[numeric_columns].mean())
    
    # Diviser les donn√©es en ensemble d'entra√Ænement et de test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Standardisation des donn√©es (Seulement pour les colonnes num√©riques)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Initialiser et entra√Æner le mod√®le Random Forest
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Pr√©diction sur les donn√©es de test
    y_pred = model.predict(X_test)

    # Calcul de l'erreur (MSE)
    mse = mean_squared_error(y_test, y_pred)
    
    return model, mse, X_train, X_test, y_test, y_pred

# Interface utilisateur simplifi√©e pour la pr√©diction
def show_prediction_interface(df):
    st.subheader("Pr√©diction des ventes")
    
    # V√©rifier si les colonnes 'date' et 'produit' existent, puis les exclure de la s√©lection
    excluded_columns = ['date', 'produit']
    
    # Convert all columns to lowercase for consistent exclusion
    df.columns = df.columns.str.lower()
    
    # Check for existing columns in df to exclude
    selectable_columns = [col for col in df.columns if col not in excluded_columns]

    st.write(f"Colonnes disponibles apr√®s exclusion: {selectable_columns}")  # Debugging step

    # Si aucune colonne n'est disponible pour la pr√©diction apr√®s exclusion
    if len(selectable_columns) == 0:
        st.error("Aucune colonne valide disponible pour la pr√©diction apr√®s exclusion de 'date' et 'produit'.")
        return

    target_column = st.selectbox(
        "S√©lectionnez la colonne cible (Ventes) √† pr√©dire :",
        selectable_columns
    )

    # Bouton pour entra√Æner le mod√®le et afficher les r√©sultats
    if st.button("Lancer la pr√©diction"):
        model, mse, X_train, X_test, y_test, y_pred = train_random_forest(df, target_column)
        st.success(f"Mod√®le entra√Æn√© avec succ√®s ! L'erreur moyenne quadratique (MSE) est de : {mse:.2f}")

        # Explication sur les r√©sultats de la pr√©diction
        st.write("""
            **Interpr√©tation de l'erreur quadratique moyenne (MSE)** :
            - Le MSE mesure l'√©cart moyen entre les valeurs pr√©dites et les valeurs r√©elles.
            - Une valeur basse indique que les pr√©dictions sont proches des valeurs r√©elles.
            - Un MSE √©lev√© peut sugg√©rer que le mod√®le a besoin d'am√©liorations ou que les donn√©es sont trop complexes.
        """)

        # Affichage des r√©sultats de la pr√©diction
        results_df = pd.DataFrame({"Valeurs r√©elles": y_test, "Pr√©dictions": y_pred})
        st.write("Voici les r√©sultats des pr√©dictions :")
        st.write(results_df)

        # Explication des r√©sultats
        st.write("""
            **Interpr√©tation des pr√©dictions :**
            - Les 'Valeurs r√©elles' repr√©sentent les ventes r√©elles dans vos donn√©es.
            - Les 'Pr√©dictions' sont les ventes pr√©dites par le mod√®le Random Forest.
            - Une grande diff√©rence entre les valeurs r√©elles et les pr√©dictions indique un ajustement imparfait.
        """)

        # Pr√©diction sur de nouvelles donn√©es (optionnel)
        st.subheader("Pr√©dire de nouvelles donn√©es")
        file_new_data = st.file_uploader("T√©l√©chargez un fichier de nouvelles donn√©es pour la pr√©diction", type=['csv', 'xlsx'])
        
        if file_new_data is not None:
            new_data = load_data(file_new_data)
            if new_data is not None:
                # Conversion des colonnes datetime dans les nouvelles donn√©es
                new_data = convert_datetime_columns(new_data)

                # G√©rer les valeurs manquantes et l'encodage pour les nouvelles donn√©es
                new_data_encoded = pd.get_dummies(new_data, drop_first=True)
                missing_cols = set(X_train.columns) - set(new_data_encoded.columns)
                for col in missing_cols:
                    new_data_encoded[col] = 0
                
                # Standardiser les nouvelles donn√©es
                scaler = StandardScaler()
                new_data_scaled = scaler.fit_transform(new_data_encoded)

                # Effectuer la pr√©diction
                predictions = model.predict(new_data_scaled)
                st.write("**R√©sultats de la pr√©diction sur les nouvelles donn√©es :**")
                st.write(predictions)

                # Explication des r√©sultats
                st.write("""
                    **Interpr√©tation des pr√©dictions sur de nouvelles donn√©es :**
                    - Les valeurs affich√©es sont les pr√©dictions effectu√©es par le mod√®le pour les nouvelles donn√©es.
                    - Ces r√©sultats repr√©sentent une estimation des ventes futures en fonction des caract√©ristiques fournies.
                """)

# Fonction principale pour l'upload et l'affichage
def main():
    st.title("üìä Dashboard de Pr√©diction des Ventes")
    st.write("Ce tableau de bord utilise un mod√®le Random Forest pour pr√©dire les ventes √† partir de vos donn√©es.")

    # T√©l√©chargement du fichier
    file = st.sidebar.file_uploader("T√©l√©chargez un fichier CSV ou Excel", type=['csv', 'xlsx'])
    df = load_data(file)

    if df is not None:
        # Affichage du tableau de bord de pr√©diction
        show_heatmap(df)
        show_prediction_interface(df)

if __name__ == "__main__":
    main()
